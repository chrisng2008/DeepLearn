# 残差网络 ResNet
如何看待模型复杂度。比如我们看非嵌套函数类，$\mathcal{F}_6、\mathcal{F}_5、\mathcal{F}_4、\mathcal{F}_ 3$等等。其中$\mathcal{F}_6$包含了$\mathcal{F}_{1 - 5}$, 因此我们可以认为$\mathcal{F}_6$模型是最复杂的。假设最优解为$f^*$。模型越复杂，其实并不意味着更靠近最优解。
更复杂的模型一定会带来好处吗？不一定。例如非嵌套函数类，模型越复杂，但是结果不一定会更好，甚至会更差。
但是，如果我们换一种思路，如果我们在使模型变得更复杂的同时，如果能够让新模型包含之前的模型，那么模式至少不会更差，就是不会退化。

![图 1](assest/%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C/IMG_20220909-215255229.png)  

## 残差块
- 窜连一个层改变函数类，我们以往能扩大函数类
- 残差块加入快速通道(右边)来得到$f(x)=x+g(x)$的结构

![图 2](assest/%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9C/IMG_20220909-222843911.png)  

### ResNet
- 高宽减半ResNet块(步幅2)
- 后接多个高宽不变的ResNet块

### ResNet架构
- 类似于VGG和GoogLeNet的总体架构
- 但替换成了ResNet块

## 总结
- 残差块使得很深的网络更加容易训练
  - 甚至可以训练一千层的网络
- 残差网络对随后的深层神经网络设计产生了深远影响，无论是卷积类网络还是全连接网络

## Q&A
1. f(x) = x + g(x) ：是否能够保证至少不会变坏。因为x已经拟合的很好了，如果g(x)的话，通常不会发生太大的变化。因此通常拿不到什么梯度，对结果不会有什么影响。ResNet在加深的时候，通常不会让模型变得更坏。

