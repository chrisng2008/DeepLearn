# 权重衰退

- 使用均方范数作为硬件限制
    $$
        \min \ell (w, b)\ \  \text{subject\ to}\ \left \| w \right \|^2 \leq \theta
    $$
    - 通常不限制偏移b(限不限制都差不多)
    - 小的$\theta$意味折更强的正则项

- 对每个$\theta$， 都可以找到$\lambda$使得之前的目标函数等价于下面
    $$
        \min \ell(w, b) + \frac{\lambda}{2}\left \|w \right \|^2
    $$
    - 可以通过拉格朗日乘子来证明

- 超参数$\lambda$控制了正则项的重要程度
  - $\lambda$ = 0:无作用
  - $\lambda \rightarrow \infin, w^* \rightarrow 0$

$\left \|w \right \|^2$实际上一个惩罚的项

### 参数更新法则
- 计算梯度
    $$
        \frac{\partial}{\partial w}(\ell (w, b) + \frac{\lambda}{2}\left \|w \right \|^2) = \frac{\partial \ell (w, b)}{\partial w} + \lambda w
    $$
- 时间t更新参数
    $$
        w_{t+1} = (1-\eta \lambda)w_t - \eta \frac{\partial \ell (w_t, b_t)}{\partial w_t}
    $$
    - 通常$\eta \lambda < 1$, 在深度学习中通常叫做权重衰退

## 总结
- 权重衰退通过L2正则项使得模型参数不会过大，从而控制了模型的复杂度
- 正则项权重是控制模型复杂度的超参数